{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-08T15:18:17.100044Z",
     "start_time": "2024-07-08T15:18:17.097495Z"
    }
   },
   "source": [
    "import math\n",
    "from torch.utils.data import DataLoader\n",
    "import glob\n",
    "from glob import glob\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import tqdm\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "from torch.utils.data import Dataset\n",
    "import albumentations as A\n",
    "import timm\n",
    "import torch\n",
    "from torch import nn"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T15:18:17.105775Z",
     "start_time": "2024-07-08T15:18:17.101092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "warnings.filterwarnings(\"ignore\", category=SettingWithCopyWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "DATA_PATH = Path(\"/mnt/Cache/rsna-2024-lumbar-spine-degenerative-classification\")\n",
    "rd = '/mnt/Cache/rsna-2024-lumbar-spine-degenerative-classification'\n"
   ],
   "id": "e34574f1e8bbd51d",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T15:18:17.109039Z",
     "start_time": "2024-07-08T15:18:17.106472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class RSNA24Model(nn.Module):\n",
    "    def __init__(self, model_name, in_c=3, n_classes=30, pretrained=True, features_only=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(\n",
    "            model_name,\n",
    "            pretrained=pretrained,\n",
    "            features_only=features_only,\n",
    "            in_chans=in_c,\n",
    "            num_classes=n_classes,\n",
    "            global_pool='avg'\n",
    "        )\n",
    "        # print(torchinfo.summary(self.model, (IN_CHANS, *IMG_SIZE)))\n",
    "        print(f\"Params: {(torch.nn.utils.parameters_to_vector(self.model.parameters()).numel()/1000000):.2f}M\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.model(x)\n",
    "        return y\n"
   ],
   "id": "120b0dee22e82042",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T15:18:17.118695Z",
     "start_time": "2024-07-08T15:18:17.110032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_dicom(path):\n",
    "    try:\n",
    "        dicom = pydicom.read_file(path)\n",
    "        data = dicom.pixel_array\n",
    "        data = data - np.min(data)\n",
    "        if np.max(data) != 0:\n",
    "            data = data / np.max(data)\n",
    "        data = (data * 255).astype(np.uint8)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        data = np.zeros((200, 200)).astype(np.uint8)\n",
    "    return data\n",
    "\n",
    "\n",
    "def process_axial(transformed):\n",
    "    transformed1 = A.Compose([\n",
    "        A.InvertImg(always_apply=True),\n",
    "    ])(image=transformed)[\"image\"]\n",
    "\n",
    "    transformed2 = A.Compose([\n",
    "        A.Equalize(always_apply=True)\n",
    "    ])(image=transformed)[\"image\"]\n",
    "\n",
    "    transformed3 = A.Compose([\n",
    "        A.Crop(always_apply=False, p=1.0, x_min=100, y_min=100, x_max=220, y_max=220),\n",
    "        A.Resize(300, 300),\n",
    "    ])(image=transformed)[\"image\"]\n",
    "\n",
    "    transformed4 = A.Compose([\n",
    "        A.InvertImg(always_apply=True),\n",
    "    ])(image=transformed3)[\"image\"]\n",
    "\n",
    "    transformed5 = A.Compose([\n",
    "        A.Equalize(always_apply=True)\n",
    "    ])(image=transformed3)[\"image\"]\n",
    "\n",
    "    transformed6 = A.Compose([\n",
    "        A.Crop(always_apply=False, p=1.0, x_min=150, y_min=100, x_max=240, y_max=220),\n",
    "        A.Resize(300, 300)\n",
    "    ])(image=transformed)[\"image\"]\n",
    "\n",
    "    transformed7 = A.Compose([\n",
    "        A.InvertImg(always_apply=True),\n",
    "    ])(image=transformed6)[\"image\"]\n",
    "\n",
    "    transformed8 = A.Compose([\n",
    "        A.Equalize(always_apply=True),\n",
    "    ])(image=transformed6)[\"image\"]\n",
    "\n",
    "    return np.vstack((\n",
    "        np.hstack((transformed, transformed1, transformed2)),\n",
    "        np.hstack((transformed3, transformed4, transformed5)),\n",
    "        np.hstack((transformed6, transformed7, transformed8))\n",
    "    ))\n",
    "\n",
    "\n",
    "def process_sagittal(transformed):\n",
    "    transformed1 = A.Compose([\n",
    "        A.InvertImg(always_apply=True),\n",
    "    ])(image=transformed)[\"image\"]\n",
    "\n",
    "    transformed2 = A.Compose([\n",
    "        A.Sharpen(always_apply=True, alpha=(0.2, 0.2), lightness=(3, 3), p=0.75)\n",
    "    ])(image=transformed)[\"image\"]\n",
    "\n",
    "    transformed3 = A.Compose([\n",
    "        A.Crop(always_apply=True, p=1.0, x_min=40, y_min=40, x_max=200, y_max=240),\n",
    "        A.Resize(300, 300),\n",
    "    ])(image=transformed)[\"image\"]\n",
    "\n",
    "    transformed4 = A.Compose([\n",
    "        A.InvertImg(always_apply=True),\n",
    "    ])(image=transformed3)[\"image\"]\n",
    "\n",
    "    transformed5 = A.Compose([\n",
    "        A.Sharpen(always_apply=True, alpha=(0.2, 0.2), lightness=(3, 3), p=0.75)\n",
    "    ])(image=transformed3)[\"image\"]\n",
    "\n",
    "    transformed6 = A.Compose([\n",
    "        A.Equalize(always_apply=True)\n",
    "    ])(image=transformed3)[\"image\"]\n",
    "\n",
    "    transformed7 = A.Compose([\n",
    "        A.Equalize(always_apply=True)\n",
    "    ])(image=transformed)[\"image\"]\n",
    "\n",
    "    transformed8 = A.Compose([\n",
    "        A.Downscale(always_apply=False, scale_min=0.099, scale_max=0.099)\n",
    "    ])(image=transformed3)[\"image\"]\n",
    "\n",
    "    return np.vstack((\n",
    "        np.hstack((transformed, transformed1, transformed2)),\n",
    "        np.hstack((transformed3, transformed4, transformed5)),\n",
    "        np.hstack((transformed6, transformed7, transformed8))\n",
    "    ))\n",
    "\n",
    "\n",
    "def validation_transform(height, width):\n",
    "    return A.Compose([\n",
    "            A.Resize(height, width),\n",
    "            A.Normalize(mean=0.5, std=0.5),\n",
    "            A.ToRGB()\n",
    "        ])\n",
    "\n",
    "\n",
    "def resize_transform():\n",
    "    return A.Compose([\n",
    "        A.Resize(300, 300),\n",
    "    ])\n",
    "\n",
    "\n",
    "class RSNA24DatasetInference(Dataset):\n",
    "    def __init__(self, dataframe, image_dir, image_size):\n",
    "        self.df = dataframe\n",
    "        self.study_ids = list(self.df['study_id'].unique())\n",
    "        self.image_dir = image_dir\n",
    "        self.resize = resize_transform()\n",
    "        self.common_transform = validation_transform(image_size[0], image_size[1])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.df.iloc[idx]\n",
    "        image = load_dicom(f\"{self.image_dir}/{x['study_id']}/{x['series_id']}/{x['instance_number']}.dcm\")\n",
    "\n",
    "        image = self.resize(image=image)[\"image\"]\n",
    "\n",
    "        if x.series_description == \"Sagittal T2/STIR\" or x.series_description == \"Sagittal T1\":\n",
    "            image = process_sagittal(image)\n",
    "        if x.series_description == \"Axial T2\":\n",
    "            image = process_axial(image)\n",
    "\n",
    "        image = self.common_transform(image=image)[\"image\"]\n",
    "        image = image.transpose(2, 0, 1).astype(np.float32)\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "class RSNA24DatasetActivation(Dataset):\n",
    "    def __init__(self, st_ids, sagittal_t2_feat, sagittal_t1_feat, axial_t2_feat):\n",
    "        self.sagittal_t2_feat = sagittal_t2_feat\n",
    "        self.sagittal_t1_feat = sagittal_t1_feat\n",
    "        self.axial_t2_feat = axial_t2_feat\n",
    "\n",
    "        self.study_ids = st_ids\n",
    "\n",
    "        self.image_size = (240, 240)\n",
    "        self.label = \"full_label\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.study_ids)\n",
    "\n",
    "    def create_image(self, data):\n",
    "        data = data.sort_values(\"instance_number\")\n",
    "        data = [np.array(i) for i in data.preds.values]\n",
    "        return cv2.resize(np.array(data), self.image_size, interpolation=cv2.INTER_AREA).transpose((2, 0, 1))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        study_id = self.study_ids[i]\n",
    "        xs2 = self.create_image(self.sagittal_t2_feat.loc[self.sagittal_t2_feat.study_id == study_id])\n",
    "        xs1 = self.create_image(self.sagittal_t1_feat.loc[self.sagittal_t1_feat.study_id == study_id])\n",
    "        xt1 = self.create_image(self.axial_t2_feat.loc[self.axial_t2_feat.study_id == study_id])\n",
    "        feat = np.vstack((xs2, xs1, xt1))\n",
    "        return feat.astype(np.float32), study_id\n"
   ],
   "id": "d609a30657f585d3",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T15:18:17.123624Z",
     "start_time": "2024-07-08T15:18:17.119447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "\n",
    "class ModelConfig:\n",
    "    MODEL_PATH = 'rsna24-data/models_db/xception41-DB-c3p1b16e20f14/'\n",
    "    MODEL_FILENAME = 'axial_t2-best_wll_model_fold-0.pt'\n",
    "    MODEL_NAME = \"xception41\"\n",
    "\n",
    "    IMG_SIZE = [512, 512]\n",
    "    IN_CHANS = 3\n",
    "\n",
    "    N_LABELS = 10\n",
    "    N_CLASSES = 30\n",
    "\n",
    "    def __init__(self, path=None):\n",
    "        if path is not None:\n",
    "            self.load(path)\n",
    "\n",
    "    def load(self, path):\n",
    "        with open(path, 'r') as f:\n",
    "            config = json.load(f)\n",
    "            self.__dict__.update(config)\n",
    "\n",
    "    def save(self, path):\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(self.__dict__, f, indent=4)\n"
   ],
   "id": "7986fe7d7095cbea",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T15:18:17.137103Z",
     "start_time": "2024-07-08T15:18:17.124459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sagittal_t2_model_config = ModelConfig(\"rsna24-data/models_db/xception41-DB-c3p1b16e20f14/axial_t2-best_wll_model_fold-0.json\")\n",
    "sagittal_t1_model_config = ModelConfig(\"rsna24-data/models_db/xception41-DB-c3p1b16e20f14/sagittal_t1-best_wll_model_fold-0.json\")\n",
    "axial_t2_model_config = ModelConfig(\"rsna24-data/models_db/xception41-DB-c3p1b16e20f14/sagittal_t2-best_wll_model_fold-0.json\")\n",
    "activation_model_config = ModelConfig(\"rsna24-data/models/rexnet_150.nav_in1k-A-c9p1b16e20f14/Activation-best_wll_model_fold-0.json\")\n",
    "\n",
    "N_WORKERS = math.floor(os.cpu_count()/2) + 1\n",
    "USE_AMP = True\n",
    "SEED = 8620\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "autocast = torch.cuda.amp.autocast(enabled=USE_AMP, dtype=torch.half)\n",
    "\n",
    "sample_sub = pd.read_csv(f'{rd}/sample_submission.csv')\n",
    "LABELS = list(sample_sub.columns[1:])\n",
    "CONDITIONS = [\n",
    "    'spinal_canal_stenosis',\n",
    "    'left_neural_foraminal_narrowing',\n",
    "    'right_neural_foraminal_narrowing',\n",
    "    'left_subarticular_stenosis',\n",
    "    'right_subarticular_stenosis'\n",
    "]\n",
    "\n",
    "LEVELS = [\n",
    "    'l1_l2',\n",
    "    'l2_l3',\n",
    "    'l3_l4',\n",
    "    'l4_l5',\n",
    "    'l5_s1',\n",
    "]\n",
    "\n",
    "plane_conditions = {\n",
    "    \"Sagittal T2/STIR\": [\"spinal_canal_stenosis\"],\n",
    "    \"Sagittal T1\": [\"left_neural_foraminal_narrowing\", \"right_neural_foraminal_narrowing\"],\n",
    "    \"Axial T2\": [\"left_subarticular_stenosis\", \"right_subarticular_stenosis\"]\n",
    "}\n",
    "levels = [\"l1_l2\", \"l2_l3\", \"l3_l4\", \"l4_l5\", \"l5_s1\"]\n",
    "row_names = {\n",
    "    \"Sagittal T2/STIR\": [],\n",
    "    \"Sagittal T1\": [],\n",
    "    \"Axial T2\": []\n",
    "}\n",
    "for k in plane_conditions:\n",
    "    for p in plane_conditions[k]:\n",
    "        for label in levels:\n",
    "            row_names[k].append(f\"{p}_{label}\")\n",
    "\n",
    "labels = [\"row_id\", \"normal_mild\", \"moderate\", \"severe\"]\n",
    "\n",
    "\n",
    "def get_model_output(data, config: ModelConfig, image_dir):\n",
    "    model = RSNA24Model(config.MODEL_NAME, config.IN_CHANS, config.N_CLASSES, pretrained=False)\n",
    "    model.load_state_dict(torch.load(config.MODEL_PATH + \"/\" + config.MODEL_FILENAME))\n",
    "    model.eval()\n",
    "    model.half()\n",
    "    model.to(device)\n",
    "\n",
    "    dataset = RSNA24DatasetInference(data, image_dir, config.IMG_SIZE)\n",
    "    dl = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=N_WORKERS, pin_memory=False, drop_last=False)\n",
    "\n",
    "    y_preds = []\n",
    "    with tqdm.tqdm(total=len(dl), leave=True) as pbar:\n",
    "        with torch.no_grad():\n",
    "            for idx, x in enumerate(dl):\n",
    "                x = x.to(device).type(torch.float32)\n",
    "                with autocast:\n",
    "                    y = model(x).reshape(-1, config.N_LABELS, 3).softmax(2)\n",
    "                    y = y.cpu().numpy()\n",
    "                    y_preds.append(y)\n",
    "\n",
    "                pbar.update()\n",
    "\n",
    "    del model\n",
    "    y_preds = np.concatenate(y_preds, axis=0)\n",
    "    data[\"preds\"] = y_preds.tolist()\n",
    "    return data\n",
    "\n",
    "\n",
    "def apply_average(x):\n",
    "    preds = []\n",
    "    if x.iloc[0].series_description == \"Sagittal T2/STIR\":\n",
    "        preds = np.array([np.array(y) for y in x[\"preds\"].values]).mean(0)\n",
    "\n",
    "    if x.iloc[0].series_description == \"Sagittal T1\":\n",
    "        preds = np.array([np.array(y) for y in x[\"preds\"].values]).mean(0)\n",
    "\n",
    "    if x.iloc[0].series_description == \"Axial T2\":\n",
    "        x['instance_number'] = x['instance_number'].astype('int32')\n",
    "        x = x.sort_values(by=[\"instance_number\"])\n",
    "        step = math.floor(x.shape[0]/5)\n",
    "        left = []\n",
    "        right = []\n",
    "        for i in range(0, 5):\n",
    "            y = x.iloc[i*step:(i * step)+step]\n",
    "            preds = np.array([np.array(z) for z in y[\"preds\"].values]).mean(0)\n",
    "            left.append(preds[0])\n",
    "            right.append(preds[1])\n",
    "\n",
    "        preds = np.array(left + right)\n",
    "\n",
    "    result = []\n",
    "    for level, pred in zip(row_names[x.iloc[0].series_description], preds):\n",
    "        result.append([f\"{x.iloc[0]['study_id']}_{level}\"] + list(pred))\n",
    "    result = pd.DataFrame(result, columns=labels)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def average_method(sagittal_t2, sagittal_t1, axial_t2):\n",
    "    sagittal_t2 = sagittal_t2.groupby(by=[\"study_id\", \"series_id\"]).apply(lambda x: apply_average(x)).reset_index(drop=True)\n",
    "    sagittal_t1 = sagittal_t1.groupby(by=[\"study_id\", \"series_id\"]).apply(lambda x: apply_average(x)).reset_index(drop=True)\n",
    "    axial_t2 = axial_t2.groupby(by=[\"study_id\", \"series_id\"]).apply(lambda x: apply_average(x)).reset_index(drop=True)\n",
    "\n",
    "    return pd.concat([sagittal_t1, axial_t2, sagittal_t2]).sort_values(\"row_id\")\n",
    "\n",
    "\n",
    "def activation_method(dataset, config: ModelConfig, sagittal_t2, sagittal_t1, axial_t2):\n",
    "    test_ds = RSNA24DatasetActivation(\n",
    "        dataset.study_id.unique(),\n",
    "        sagittal_t2,\n",
    "        sagittal_t1,\n",
    "        axial_t2,\n",
    "    )\n",
    "    test_dl = DataLoader(\n",
    "        test_ds, batch_size=1, shuffle=False, pin_memory=False, drop_last=False, num_workers=N_WORKERS\n",
    "    )\n",
    "    model = RSNA24Model(config.MODEL_NAME, in_c=config.IN_CHANS, n_classes=config.N_CLASSES, pretrained=False)\n",
    "    model.load_state_dict(torch.load(config.MODEL_PATH + \"/\" + config.MODEL_FILENAME))\n",
    "    model.eval()\n",
    "    model.half()\n",
    "    model.to(device)\n",
    "\n",
    "    y_preds = []\n",
    "    row_names = []\n",
    "    with tqdm.tqdm(test_dl, leave=True) as pbar:\n",
    "        with torch.no_grad():\n",
    "            for idx, (x, study_id) in enumerate(pbar):\n",
    "                x = x.to(device)\n",
    "                for cond in CONDITIONS:\n",
    "                    for level in LEVELS:\n",
    "                        row_names.append(str(study_id[0].item()) + '_' + cond + '_' + level)\n",
    "\n",
    "                pred_per_study = np.zeros((25, 3))\n",
    "                with autocast:\n",
    "                    y = model(x)[0]\n",
    "                    for col in range(config.N_LABELS):\n",
    "                        pred = y[col * 3:col * 3 + 3]\n",
    "                        y_pred = pred.float().softmax(0).cpu().numpy()\n",
    "                        pred_per_study[col] += y_pred\n",
    "                y_preds.append(pred_per_study)\n",
    "    del model\n",
    "    y_preds = np.concatenate(y_preds, axis=0)\n",
    "    sub = pd.DataFrame()\n",
    "    sub['row_id'] = row_names\n",
    "    sub[LABELS] = y_preds\n",
    "    return sub\n",
    "\n",
    "\n",
    "def inject_series_description(x):\n",
    "    rows = pd.DataFrame([\n",
    "        [x.iloc[0].study_id, -100, \"Axial T2\"],\n",
    "        [x.iloc[0].study_id, -100, 'Sagittal T2/STIR'],\n",
    "        [x.iloc[0].study_id, -100, \"Sagittal T1\"]\n",
    "    ], columns=[\"study_id\", \"series_id\", \"series_description\"])\n",
    "\n",
    "    rows = pd.concat([x, rows]).drop_duplicates(subset=[\"study_id\", \"series_description\"], keep=\"first\")\n",
    "    return rows\n",
    "\n",
    "\n",
    "def instance_image_path(x, image_dir):\n",
    "    return [\n",
    "        os.path.splitext(os.path.basename(d))[0] for d in glob(f\"{image_dir}/{x['study_id']}/{x['series_id']}/*.dcm\")\n",
    "    ]\n",
    "\n",
    "\n",
    "def prepare_submission(dataset, image_dir, activation_model, sagittal_model_t2, sagittal_model_t1, axial_model_t1, method=\"average\"):\n",
    "    # TODO utilize all data\n",
    "    dataset = dataset.drop_duplicates(subset=[\"study_id\", \"series_description\"])\n",
    "    dataset = dataset.groupby(\"study_id\").apply(lambda x: inject_series_description(x)).reset_index(drop=True)\n",
    "    dataset[\"instance_number\"] = dataset.apply(lambda x: instance_image_path(x, image_dir), axis=1)\n",
    "    dataset = dataset.explode(\"instance_number\")\n",
    "\n",
    "    sagittal_t2 = get_model_output(\n",
    "        dataset.loc[dataset.series_description == \"Sagittal T2/STIR\"],\n",
    "        sagittal_model_t2,\n",
    "        image_dir\n",
    "    )\n",
    "\n",
    "    sagittal_t1 = get_model_output(\n",
    "        dataset.loc[dataset.series_description == \"Sagittal T1\"],\n",
    "        sagittal_model_t1,\n",
    "        image_dir\n",
    "    )\n",
    "\n",
    "    axial_t2 = get_model_output(\n",
    "        dataset.loc[dataset.series_description == \"Axial T2\"],\n",
    "        axial_model_t1,\n",
    "        image_dir\n",
    "    )\n",
    "    if method == \"activation\":\n",
    "        sub = activation_method(dataset, activation_model, sagittal_t2, sagittal_t1, axial_t2)\n",
    "    else:\n",
    "        sub = average_method(sagittal_t2, sagittal_t1, axial_t2)\n",
    "\n",
    "    return sub.reset_index(drop=True)"
   ],
   "id": "39b0a2cda1993811",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T15:18:20.648680Z",
     "start_time": "2024-07-08T15:18:17.137882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "df = pd.read_csv(f'{rd}/test_series_descriptions.csv')\n",
    "submission = prepare_submission(\n",
    "    df,\n",
    "    f\"{rd}/test_images/\",\n",
    "    activation_model_config,\n",
    "    sagittal_t2_model_config,\n",
    "    sagittal_t1_model_config,\n",
    "    axial_t2_model_config,\n",
    "    \"activation\"\n",
    "    # \"average\"\n",
    ")\n",
    "print(submission.shape)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(pd.read_csv('submission.csv').head().to_string())"
   ],
   "id": "b27a0642b4535824",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: 24.93M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: 24.98M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: 24.95M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: 7.95M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 4)\n",
      "                                 row_id  normal_mild  moderate    severe\n",
      "0  44036939_spinal_canal_stenosis_l1_l2     0.039906  0.224212  0.735882\n",
      "1  44036939_spinal_canal_stenosis_l2_l3     0.245176  0.472258  0.282566\n",
      "2  44036939_spinal_canal_stenosis_l3_l4     0.419168  0.548838  0.031993\n",
      "3  44036939_spinal_canal_stenosis_l4_l5     0.187570  0.263549  0.548881\n",
      "4  44036939_spinal_canal_stenosis_l5_s1     0.142937  0.139626  0.717437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
